# -*- coding: utf-8 -*-
"""Laboratorio2SP1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S410ljhzxZuZufni50-R2k8OGEYZO02I

# Imports
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import tensorflow as tf
import tensorflow_hub as hub

from tensorflow.keras import Sequential
from tensorflow.keras.utils import get_file
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import shutil
import numpy as np
import PIL.Image as Image
import matplotlib.pylab as plt

seed=1998
np.random.seed(seed)
tf.random.set_seed(seed)

!pip install googleimagedownloader

from googleimagedownloader.googleimagedownloader import GoogleImageDownloader

"""# Testing an pretrained classifier"""

IMAGE_SIZE = (224,224)

# classifier_url = 'https://tfhub.dev/google/imagenet/resnet_v2_152/feature_vector/4'
# classifier_url = 'https://tfhub.dev/google/imagenet/resnet_v2_152/classification/4'
# classifier_url = 'https://tfhub.dev/google/imagenet/resnet_v2_101/classification/4'
classifier_url ="https://tfhub.dev/google/imagenet/resnet_v2_50/classification/4"

classifier = Sequential([
  hub.KerasLayer(classifier_url, input_shape=IMAGE_SIZE+(3,))
])

test_image = get_file('buff.jpg', 'https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i3Yp1mXpDIMA/v2/1000x-1.jpg')
test_image = Image.open(test_image).resize(IMAGE_SIZE)
test_image

test_image = np.array(test_image)/255.0
test_image.shape

result = classifier.predict(test_image[np.newaxis, ...])
result.shape

predicted_class = np.argmax(result[0], axis=-1)
predicted_class

labels_path = get_file('ImageNetLabels.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')
imagenet_labels = np.array(open(labels_path).read().splitlines())

predicted_class_name = imagenet_labels[predicted_class]
plt.axis('off')
plt.title("Label: " + predicted_class_name, color = 'black')
plt.imshow(test_image)
plt.show()

"""# Creating the Transfer Learning Model

## Create the Eeveelutions dataset
"""

# Eeveelutions Classifier :D 
# class_names = ['flareon', 'jolteon', 'vaporeon', 'umbreon', 'espeon', 'glaceon', 'sylveon', 'leafeon']
class_names = ['flareon', 'jolteon', 'vaporeon']
# class_names = ['flareon', 'jolteon']
path = 'eevelutions/dataset/'

train_dir = os.path.join(path, 'train')
validation_dir = os.path.join(path, 'validation')

train_fla_dir = os.path.join(train_dir, 'flareon')  
train_jol_dir = os.path.join(train_dir, 'jolteon')  
# train_vap_dir = os.path.join(train_dir, 'vaporeon')  
# train_umb_dir = os.path.join(train_dir, 'umbreon')
# train_esp_dir = os.path.join(train_dir, 'espeon')
# train_gla_dir = os.path.join(train_dir, 'glaceon')
# train_syl_dir = os.path.join(train_dir, 'sylveon')
# train_lea_dir = os.path.join(train_dir, 'leafeon')

validation_fla_dir = os.path.join(validation_dir, 'flareon') 
validation_jol_dir = os.path.join(validation_dir, 'jolteon')
# validation_vap_dir = os.path.join(validation_dir, 'vaporeon')
# validation_umb_dir = os.path.join(validation_dir, 'umbreon')
# validation_esp_dir = os.path.join(validation_dir, 'espeon')
# validation_gla_dir = os.path.join(validation_dir, 'glaceon')
# validation_syl_dir = os.path.join(validation_dir, 'sylveon')
# validation_lea_dir = os.path.join(validation_dir, 'leafeon')

if os.path.exists(path):
  shutil.rmtree(path)

os.makedirs(train_fla_dir)
os.makedirs(train_jol_dir)
# os.makedirs(train_vap_dir)
# os.makedirs(train_umb_dir)
# os.makedirs(train_esp_dir)
# os.makedirs(train_gla_dir)
# os.makedirs(train_syl_dir)
# os.makedirs(train_lea_dir)

os.makedirs(validation_fla_dir)    
os.makedirs(validation_jol_dir)
# os.makedirs(validation_vap_dir)
# os.makedirs(validation_umb_dir)
# os.makedirs(validation_esp_dir)
# os.makedirs(validation_gla_dir)
# os.makedirs(validation_syl_dir)
# os.makedirs(validation_lea_dir)

def manage_images(src, dest_train, dest_val, image_resize=IMAGE_SIZE, val_split=0.1, prefix=''):
  total = len(os.listdir(src))
  val = np.int(total*val_split)
  count = 0
  files = os.listdir(src)

  for file_name in files:
    try:
      dest = dest_train if count >= val else dest_val
      dest_file = os.path.join(dest, prefix + file_name) 

      img = Image.open(os.path.join(src,file_name))
      img.verify()
      # reopen because verify() was called
      # If you need to load the image after using this method, you must reopen the image file.
      # https://pillow.readthedocs.io/en/3.1.x/reference/Image.html
      img = Image.open(os.path.join(src,file_name))
      #resize
      img = img.resize(image_resize, Image.ANTIALIAS)
      #move
      img.save(dest_file)  
      count+=1 
    except Exception as e:
        print('Invalid image: ',file_name,e)
        if os.path.exists(dest_file):
          os.remove(dest_file)
  return

img_dir = os.path.realpath('Images/')

queries = ['eevelutions','pokemon','evee', '']
pos = 0
for query in queries:
  image = GoogleImageDownloader(Query='flareon '+query, numberImage=50)
  try:
    image.downloadImages()
  except Exception as e:
    print('Error ',e)
  #verify, resize, move and split sets
  manage_images(img_dir, train_fla_dir, validation_fla_dir,prefix=str(pos)+'-')
  pos+=1

queries = ['eevelutions','pokemon','evee', '']
pos = 0
for query in queries:
  image = GoogleImageDownloader(Query='jolteon '+query, numberImage=50)
  try:
    image.downloadImages()
  except Exception as e:
    print('Error ',e)
  #verify, resize, move and split sets
  manage_images(img_dir, train_jol_dir, validation_jol_dir,prefix=str(pos)+'-')
  pos+=1

# queries = ['eevelutions','pokemon','evee', '']
# pos = 0
# for query in queries:
#   image = GoogleImageDownloader(Query='vaporeon '+query, numberImage=0)
#   try:
#     image.downloadImages()
#   except Exception as e:
#     print('Error ',e)
#   #verify, resize, move and split sets
#   manage_images(img_dir, train_vap_dir, validation_vap_dir,prefix=str(pos)+'-')
#   pos+=1

# queries = ['eevelutions','pokemon','evee', '']
# pos = 0
# for query in queries:
#   image = GoogleImageDownloader(Query='umbreon '+query, numberImage=0)
#   try:
#     image.downloadImages()
#   except Exception as e:
#     print('Error ',e)
#   #verify, resize, move and split sets
#   manage_images(img_dir, train_umb_dir, validation_umb_dir,prefix=str(pos)+'-')
#   pos+=1

# queries = ['eevelutions','pokemon','evee', '']
# pos = 0
# for query in queries:
#   image = GoogleImageDownloader(Query='espeon '+query, numberImage=0)
#   try:
#     image.downloadImages()
#   except Exception as e:
#     print('Error ',e)
#   #verify, resize, move and split sets
#   manage_images(img_dir, train_esp_dir, validation_esp_dir,prefix=str(pos)+'-')
#   pos+=1

# queries = ['eevelutions','pokemon','evee', '']
# pos = 0
# for query in queries:
#   image = GoogleImageDownloader(Query='glaceon '+query, numberImage=0)
#   try:
#     image.downloadImages()
#   except Exception as e:
#     print('Error ',e)
#   #verify, resize, move and split sets
#   manage_images(img_dir, train_gla_dir, validation_gla_dir,prefix=str(pos)+'-')
#   pos+=1

# queries = ['eevelutions','pokemon','evee', '']
# pos = 0
# for query in queries:
#   image = GoogleImageDownloader(Query='sylveon '+query, numberImage=0)
#   try:
#     image.downloadImages()
#   except Exception as e:
#     print('Error ',e)
#   #verify, resize, move and split sets
#   manage_images(img_dir, train_syl_dir, validation_syl_dir,prefix=str(pos)+'-')
#   pos+=1

# queries = ['eevelutions','pokemon','evee', '']
# pos = 0
# for query in queries:
#   image = GoogleImageDownloader(Query='leafeon '+query, numberImage=0)
#   try:
#     image.downloadImages()
#   except Exception as e:
#     print('Error ',e)
#   #verify, resize, move and split sets
#   manage_images(img_dir, train_lea_dir, validation_lea_dir,prefix=str(pos)+'-')
#   pos+=1

total_train = len(os.listdir(train_fla_dir))+ len(os.listdir(train_jol_dir)) #+ len(os.listdir(train_vap_dir))
total_val = len(os.listdir(validation_fla_dir))+ len(os.listdir(validation_jol_dir)) #+ len(os.listdir(validation_vap_dir))

print('total training Flareon images:', len(os.listdir(train_fla_dir)))
print('total training Jolteon images:', len(os.listdir(train_jol_dir)))
# print('total training Vaporeon images:', len(os.listdir(train_vap_dir)))
# print('total training Umbreon images:', len(os.listdir(train_umb_dir)))
# print('total training Espeon images:', len(os.listdir(train_esp_dir)))
# print('total training Glaceon images:', len(os.listdir(train_gla_dir)))
# print('total training Sylveon images:', len(os.listdir(train_syl_dir)))
# print('total training Leafeon images:', len(os.listdir(train_lea_dir)))

print('total validation Flareon images:', len(os.listdir(validation_fla_dir)))
print('total validation Jolteon images:', len(os.listdir(validation_jol_dir)))
# print('total validation Vaporeon images:', len(os.listdir(validation_vap_dir)))
# print('total validation Umbreon images:', len(os.listdir(validation_umb_dir)))
# print('total validation Espeon images:', len(os.listdir(validation_esp_dir)))
# print('total validation Glaceon images:', len(os.listdir(validation_gla_dir)))
# print('total validation Sylveon images:', len(os.listdir(validation_syl_dir)))
# print('total validation Leafeon images:', len(os.listdir(validation_lea_dir)))
print("--")
print("Total training images:", total_train)
print("Total validation images:", total_val)

"""## Using the Eevelutions dataset"""

train_image_generator = ImageDataGenerator(rescale=1./255)
validation_image_generator = ImageDataGenerator(rescale=1./255)

train_data_gen = train_image_generator.flow_from_directory(train_dir,
                                                           shuffle=True,
                                                           batch_size=32,
                                                           target_size=IMAGE_SIZE,
                                                           class_mode='binary')

val_data_gen = validation_image_generator.flow_from_directory(validation_dir,
                                                              target_size=IMAGE_SIZE,
                                                              class_mode='binary')



"""## Testing the pretrained classifier (Pure ResNet152)"""

image_batch, labels_batch = next(train_data_gen)

result_batch = classifier.predict(image_batch)
result_batch.shape

predicted_class_names = imagenet_labels[np.argmax(result_batch, axis=-1)]
predicted_class_names

def plot_images(img_batch, labels, predicted_labels):
  plt.figure(figsize=(12,12))
  plt.subplots_adjust(hspace=0.5)
  for i in range(15):
    plt.subplot(6,5,i+1) 
    plt.imshow(img_batch[i])
    color = "green" if predicted_labels[i] == class_names[np.int(labels[i])] else "red"
    plt.title(predicted_labels[i], color=color)
    plt.axis('off')

plot_images(image_batch, labels_batch, predicted_class_names)



"""# RESNET 152 with feature detection for Eevelutions"""

# feature_extractor_url = 'https://tfhub.dev/google/imagenet/resnet_v2_152/feature_vector/4'
# feature_extractor_url = 'https://tfhub.dev/google/imagenet/resnet_v2_101/feature_vector/4'
feature_extractor_url = "https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4"

feature_extractor_layer = hub.KerasLayer(feature_extractor_url,
                                         input_shape=IMAGE_SIZE+(3,))

feature_batch = feature_extractor_layer(image_batch)
print(feature_batch.shape)

feature_extractor_layer.trainable = False

"""## Adding the classification head"""

simple_model = Sequential([
  feature_extractor_layer,
  Dense(1024, activation='relu'),
  Dense(1, activation='sigmoid')
  # Conv2D(32, kernel_size=(3, 3),
  #                activation='relu'),
  # Conv2D(64, (3, 3), activation='relu'),
  # MaxPooling2D(pool_size=(2, 2)),
  # Dropout(0.25),
  # # Flatten(),
  # Dense(128, activation='relu'),
  # Dropout(0.5),
  # Dense(8, activation='softmax')
])


simple_model.summary()

predictions = simple_model(image_batch)
predicted_class_names = np.array(class_names)[np.rint(predictions).astype('int32')].flatten()
plot_images(image_batch, labels_batch, predicted_class_names)

"""## Training the model"""

simple_model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
# simple_model.compile(loss=tf.keras.losses.categorical_crossentropy,
#               optimizer=tf.keras.optimizers.SGD(lr=0.3),
#               metrics=['accuracy'])

history = simple_model.fit(
    train_data_gen,
    epochs=30,
    steps_per_epoch=5,
    verbose=1,
    validation_data=val_data_gen
)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
# plt.ylim([0,1.5])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

predictions = simple_model(image_batch)
predicted_class_names = np.array(class_names)[np.rint(predictions).astype('int32')].flatten()

plot_images(image_batch, labels_batch, predicted_class_names)

